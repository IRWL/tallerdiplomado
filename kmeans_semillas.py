# -*- coding: utf-8 -*-
"""Kmeans_Semillas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15W6EslzThva0tTueTvUU2UMmRZ7sMvhc

# Agrupamiento - K-Medias

Dataset:
El conjunto de datos ‚ÄúSeeds‚Äù describe 210 muestras de granos de trigo, cada una medida con 7 caracter√≠sticas.

Cada fila corresponde a un grano de trigo y se midieron variables de su geometr√≠a a partir de im√°genes escaneadas.

üîë Columnas del dataset



*   √Årea (A) ‚Üí √Årea de la semilla.
*   Per√≠metro (P) ‚Üí Longitud del contorno de la semilla.
*   Compacidad (C = 4œÄA / P¬≤) ‚Üí Qu√© tan ‚Äúcompacta‚Äù es la semilla (similar a circularidad).
*   Longitud del n√∫cleo (L) ‚Üí Largo del grano.
*   Ancho del n√∫cleo (W) ‚Üí Ancho del grano.
*   Coeficiente de asimetr√≠a (Asymmetry Coefficient) ‚Üí Medida de la simetr√≠a de la semilla.
*   Longitud del surco del n√∫cleo (Groove Length) ‚Üí Longitud del surco del grano.
*   Clase (label) ‚Üí Tipo de trigo (3 variedades distintas).

Para comenzar, ejecute la celda a continuaci√≥n para cargar nuestros datos.

> **Cita**: El conjunto de datos de semillas utilizado en este ejercicio fue publicado originalmente por el Instituto de Agrof√≠sica de la Academia Polaca de Ciencias en Lublin por Dua, D. y Graff, C. (2019) y puede descargarse del [Repositorio de Aprendizaje Autom√°tico de la UCI](http://archive.ics.uci.edu/ml), Universidad de California en Irvine, Facultad de Ciencias de la Informaci√≥n y la Computaci√≥n.

##Carga de dataset "Semillas"
"""

import pandas as pd

# üì• Cargar el dataset Seeds desde un archivo CSV en internet
!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/seeds.csv
data = pd.read_csv('seeds.csv')

# üîé Seleccionar las primeras 6 columnas como caracter√≠sticas (sin incluir la clase)
# Estas columnas son las medidas de cada semilla (√°rea, per√≠metro, compacidad, etc.)
features = data[data.columns[0:6]]

# üé≤ Mostrar una muestra aleatoria de 10 semillas con sus caracter√≠sticas
features.sample(10)

"""##Normalizaci√≥n y Transformaci√≥n"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import pandas as pd

# ‚öôÔ∏è Escalado de caracter√≠sticas num√©ricas
# Convertimos todas las variables a un mismo rango [0, 1]
# para evitar que una domine a las dem√°s por su escala.
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(features.iloc[:, 0:6])

# üß† Aplicar PCA (An√°lisis de Componentes Principales)
# Reducimos las 6 dimensiones originales a solo 2
# con el fin de visualizar la estructura de los datos.
pca = PCA(n_components=2, random_state=42)
pca_data = pca.fit_transform(scaled_data)

# ü™Ñ Convertimos los resultados en un DataFrame para interpretarlos f√°cilmente
pca_df = pd.DataFrame(pca_data, columns=["PC1", "PC2"])

# üîç Mostrar las primeras 10 observaciones transformadas
pca_df.head(10)

"""## Agrupamiento de K-Medias

En este caso utilizaremos el algoritmo K-Medias (K-Means) para generar agrupamientos o cl√∫steres de prueba. Este m√©todo de machine learning no supervisado divide un conjunto de datos en K grupos con una varianza similar. El valor de K se define de antemano seg√∫n el problema.

Proceso general del algoritmo

Inicializaci√≥n: se eligen al azar K puntos que servir√°n como los centroides iniciales.

Asignaci√≥n: cada observaci√≥n se asocia con el centroide m√°s cercano (seg√∫n la distancia euclidiana).

Actualizaci√≥n: se recalcula la posici√≥n de cada centroide como la media de los puntos que pertenecen a su grupo.

Iteraci√≥n: los pasos 2 y 3 se repiten hasta que el cambio en la posici√≥n de los centroides sea m√≠nimo o se alcance un n√∫mero m√°ximo de iteraciones.

Convergencia: cuando los centroides dejan de moverse significativamente, el modelo se considera estable.
"""

from sklearn.cluster import KMeans

# üß© Crear el modelo de K-Means con 3 grupos
# n_clusters=3 ‚Üí porque sabemos que hay tres tipos distintos de trigo
# init='k-means++' ‚Üí inicializa los centroides de forma m√°s eficiente
# n_init=50 ‚Üí repite el algoritmo varias veces con diferentes puntos iniciales
# max_iter=800 ‚Üí m√°ximo de iteraciones por ejecuci√≥n
kmeans_model = KMeans(
    n_clusters=3,
    init='k-means++',
    n_init=50,
    max_iter=800,
    random_state=42
)

# ‚öôÔ∏è Entrenar el modelo con los datos y obtener las etiquetas de cl√∫ster
# Cada semilla ser√° asignada a uno de los grupos (0, 1 o 2)
cluster_labels = kmeans_model.fit_predict(features.values)

# üëÄ Mostrar las primeras asignaciones de cl√∫ster
# Cada n√∫mero indica el grupo al que pertenece cada observaci√≥n
print("Etiquetas de cl√∫ster (primeros 15):", cluster_labels[:15])

# Commented out IPython magic to ensure Python compatibility.
# ============================================================
# üìä VISUALIZACI√ìN DE LOS CL√öSTERES CON K-MEANS
# ============================================================

import matplotlib.pyplot as plt

# Para Jupyter Notebook, esta l√≠nea asegura que los gr√°ficos
# se muestren justo debajo de la celda ejecutada.
# %matplotlib inline

# ------------------------------------------------------------
# üß© Funci√≥n para graficar los cl√∫steres resultantes
# ------------------------------------------------------------
def mostrar_clusters(puntos, etiquetas):
    """
    Dibuja los cl√∫steres generados por K-Means en un plano 2D.
    """
    # Paleta de colores y s√≠mbolos para diferenciar los grupos
    color_map = {0: "royalblue", 1: "seagreen", 2: "darkorange"}
    marker_map = {0: "o", 1: "x", 2: "s"}

    # üîπ Graficar cada punto seg√∫n su etiqueta
    for i in range(len(etiquetas)):
        plt.scatter(
            puntos[i][0], puntos[i][1],
            c=color_map[etiquetas[i]],
            marker=marker_map[etiquetas[i]],
            s=90, edgecolors="k", linewidths=0.5
        )

    # Personalizaci√≥n del gr√°fico
    plt.title("Distribuci√≥n de cl√∫steres (K-Means)")
    plt.xlabel("Componente principal 1")
    plt.ylabel("Componente principal 2")
    plt.grid(alpha=0.2)
    plt.show()

# ------------------------------------------------------------
# üöÄ Llamada a la funci√≥n de visualizaci√≥n
# ------------------------------------------------------------
# - features_2d: coordenadas en 2D obtenidas con PCA
# - cluster_labels: grupos identificados por el modelo K-Means
mostrar_clusters(features_2d, cluster_labels)

"""Los datos deben separarse en tres grupos distintos. De lo contrario, repita los dos pasos anteriores.

¬øCu√°l es la utilidad pr√°ctica de la agrupaci√≥n en cl√∫steres? En algunos casos, tendr√° datos que necesita agrupar en grupos distintos sin saber cu√°ntos hay ni qu√© indican. Por ejemplo, una organizaci√≥n de marketing podr√≠a querer separar a los clientes en segmentos distintos y luego investigar c√≥mo esos segmentos muestran diferentes comportamientos de compra.

A veces, la agrupaci√≥n en cl√∫steres se utiliza como primer paso para crear un modelo de clasificaci√≥n. Se empieza por identificar grupos distintos de puntos de datos y luego se asignan etiquetas de clase a esos grupos. Despu√©s, se pueden usar estos datos etiquetados para entrenar un modelo de clasificaci√≥n.

En el caso de los datos de semillas, las diferentes especies de semillas ya se conocen y est√°n codificadas como 0 (*Kama*), 1 (*Rosa*) o 2 (*Canadian*), por lo que podemos usar estos identificadores para comparar las clasificaciones de especies con los grupos identificados por nuestro algoritmo no supervisado.
"""

# ------------------------------------------------------------
# üåæ Obtener la columna que indica la especie real de cada semilla
# ------------------------------------------------------------
real_species = data.iloc[:, 7]
# - data.iloc[:, 7] ‚Üí selecciona la octava columna ("class") del dataset.
# - Esta variable representa la especie real de trigo (tres variedades).
# - La almacenamos en la variable real_species.

# ------------------------------------------------------------
# üé® Visualizar las semillas agrupadas por su clase real
# ------------------------------------------------------------
mostrar_clusters(features_2d, real_species.values)
# - features_2d ‚Üí coordenadas 2D de cada semilla obtenidas con PCA.
# - real_species.values ‚Üí etiquetas originales (1, 2 o 3).
#   üëâ Esto permite comparar c√≥mo se distribuyen las especies verdaderas.
#   üëâ El gr√°fico mostrar√° los grupos reales en lugar de los predichos por K-Means.

"""##Resultados"""

import matplotlib.pyplot as plt

# ------------------------------------------------------------
# üß© Funci√≥n para comparar visualmente cl√∫steres y clases reales
# ------------------------------------------------------------
def comparar_clusters(muestras, etiquetas_km, etiquetas_reales):
    """
    Muestra dos gr√°ficos lado a lado:
    - A la izquierda: los grupos generados por K-Means.
    - A la derecha: las clases reales del dataset.
    """
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # una fila, dos columnas

    # üé® Paleta de colores y s√≠mbolos
    color_map = {0: 'royalblue', 1: 'seagreen', 2: 'darkorange'}
    marker_map = {0: 'o', 1: 'x', 2: 's'}

    # ----------- Panel 1: Resultado del modelo K-Means -----------
    for i in range(len(etiquetas_km)):
        axes[0].scatter(
            muestras[i, 0], muestras[i, 1],
            c=color_map[etiquetas_km[i] % 3],
            marker=marker_map[etiquetas_km[i] % 3],
            s=90, edgecolors="k", linewidths=0.5
        )
    axes[0].set_title("Agrupamiento con K-Means")
    axes[0].set_xlabel("Componente principal 1")
    axes[0].set_ylabel("Componente principal 2")

    # ----------- Panel 2: Clases originales del dataset -----------
    for i in range(len(etiquetas_reales)):
        color = color_map[(etiquetas_reales[i] - 1) % 3]  # -1 porque las clases son 1, 2 y 3
        marker = marker_map[(etiquetas_reales[i] - 1) % 3]
        axes[1].scatter(
            muestras[i, 0], muestras[i, 1],
            c=color, marker=marker,
            s=90, edgecolors="k", linewidths=0.5
        )
    axes[1].set_title("Distribuci√≥n real de especies")
    axes[1].set_xlabel("Componente principal 1")
    axes[1].set_ylabel("Componente principal 2")

    # üñº Ajustar el espacio entre gr√°ficos
    plt.tight_layout()
    plt.show()

# üöÄ Ejecutar la comparaci√≥n
# - features_2d: datos proyectados en 2D mediante PCA
# - cluster_labels: grupos asignados por K-Means
# - real_species.values: etiquetas reales (1, 2 o 3)
comparar_clusters(features_2d, cluster_labels, real_species.values)

"""# Puede haber algunas diferencias entre las asignaciones de grupos y las etiquetas de clase, pero el modelo K-Means deber√≠a haber hecho un trabajo razonable de agrupamiento de las observaciones de modo que las semillas de la misma especie est√©n generalmente en el mismo grupo."""